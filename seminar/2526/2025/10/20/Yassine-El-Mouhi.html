<p>Modern AI systems often operate under imperfect conditions where noise, quantization, and hardware faults degrade performance. Classical approaches such as ensemble learning or variational inference address uncertainty at the model-output level but remain resource-intensive and limited in scope. In this work, we explore an alternative paradigm: incorporating three-valued (ternary) logics into arithmetic and neural computations. Unlike classical binary logic, which only distinguishes between true and false, ternary logics add a third value that explicitly represents unknown or uncertain. This additional state allows uncertainty to be represented and propagated during computation rather than being forced into premature binary decisions. To the best of our knowledge, ternary logics have never been applied to arithmetic units, despite their proven usefulness in other areas such as databases, circuit design, and reasoning systems. We design ternary adders based on different logics and study how uncertainty propagates through arithmetic operations, establishing formal properties and proofs that clarify uncertainty dynamics. At the perception level, we extend convolutional neural networks with uncertainty-aware operators, enabling models to retain and process uncertainty throughout the pipeline instead of discarding it early. By combining low-level ternary arithmetic with high-level perception models, we aim to better represent, understand, and control uncertainty, ultimately improving robustness in edge and embedded AI systems.</p>
